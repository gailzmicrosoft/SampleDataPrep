{"cells":[{"cell_type":"code","source":["# Welcome to your new notebook\n","# Type here in the cell editor to add code!\n","\n","\n","# Get detailed schema information for CustomerLocation table\n","table_name = \"UsLocation\"\n","\n","print(f\"ğŸ“Š SCHEMA ANALYSIS FOR TABLE: {table_name}\")\n","print(\"=\" * (35 + len(table_name)))\n","\n","try:\n","    # Get the table\n","    df = spark.table(table_name)\n","    \n","    print(f\"âœ… Table found: {table_name}\")\n","    # print(f\"ğŸ“‹ Row count: {df.count():,}\")\n","    print(f\"ğŸ“‹ Column count: {len(df.columns)}\")\n","    \n","    print(f\"\\nğŸ” DETAILED SCHEMA:\")\n","    print(\"-\" * 25)\n","    \n","    # Print schema with detailed information\n","    for i, field in enumerate(df.schema.fields, 1):\n","        nullable = \"NULL\" if field.nullable else \"NOT NULL\"\n","        data_type = str(field.dataType)\n","        print(f\"{i:2d}. {field.name:<25} | {data_type:<25} | {nullable}\")\n","    \n","    # print(f\"\\nğŸ“‹ COLUMN NAMES:\")\n","    # print(\"-\" * 20)\n","    # for i, col in enumerate(df.columns, 1):\n","    #     print(f\"{i:2d}. {col}\")\n","    \n","    # # Show the schema in Spark SQL format\n","    # print(f\"\\nğŸ”§ SPARK SQL SCHEMA:\")\n","    # print(\"-\" * 25)\n","    # df.printSchema()\n","\n","\n","except Exception as e:\n","    print(f\"âŒ Error accessing table {table_name}: {str(e)}\")\n","    print(f\"ğŸ’¡ Make sure you're connected to the correct lakehouse\")\n","    print(f\"ğŸ’¡ Try: spark.sql('SHOW TABLES').show() to see available tables\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":30,"statement_ids":[30],"state":"finished","livy_statement_state":"available","session_id":"19201221-3142-43d2-bc2b-6b60aef2b6aa","normalized_state":"finished","queued_time":"2025-07-22T23:05:46.155927Z","session_start_time":null,"execution_start_time":"2025-07-22T23:05:46.1571002Z","execution_finish_time":"2025-07-22T23:05:46.9804523Z","parent_msg_id":"99afb69c-b3dd-4a50-ba61-5dcac81f3832"},"text/plain":"StatementMeta(, 19201221-3142-43d2-bc2b-6b60aef2b6aa, 30, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ğŸ“Š SCHEMA ANALYSIS FOR TABLE: UsLocation\n=============================================\nâœ… Table found: UsLocation\nğŸ“‹ Column count: 3\n\nğŸ” DETAILED SCHEMA:\n-------------------------\n 1. LocationId                | StringType()              | NOT NULL\n 2. LocationName              | StringType()              | NULL\n 3. CountyCode                | StringType()              | NULL\n"]}],"execution_count":28,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"621c3be9-4eff-4e6a-92d4-971d145cb11f"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"797c8f23-4bab-45ba-ad54-4a50cd03f7a0","known_lakehouses":[{"id":"797c8f23-4bab-45ba-ad54-4a50cd03f7a0"}],"default_lakehouse_name":"RDS_Fabric_Foundry_workspace_Gaiye_Retail_Solution_Test_LH_silver","default_lakehouse_workspace_id":"88ef0969-45fb-42dd-af36-283224c74eed"}}},"nbformat":4,"nbformat_minor":5}