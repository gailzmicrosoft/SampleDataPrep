{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "433e03f0",
   "metadata": {},
   "source": [
    "Generate Create Table Statments for all tables in the lakehouse and (not working yet: save it to as text file in the Lakehouse Files folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be07075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "# Import required libraries and setup\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "TARGET_SCHEMA_NAME = \"retail\"  # Change this to your desired schema name\n",
    "\n",
    "print(f\"üîç Generating CREATE TABLE statements for all lakehouse tables\")\n",
    "print(f\"üéØ Target schema name: {TARGET_SCHEMA_NAME}\")\n",
    "print(f\"üïê Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0ae38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "# Setup output path using a different folder\n",
    "import os\n",
    "\n",
    "# Try Files/create_tables_text folder instead\n",
    "output_folder = 'Files/create_tables_text/'\n",
    "output_filename = 'CreateTablesText.txt'\n",
    "output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "print(f\"üìÅ Output file path: {output_path}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3\n",
    "# Get all tables in the lakehouse\n",
    "try:\n",
    "    tables_df = spark.sql(\"SHOW TABLES\")\n",
    "    all_tables = [row['tableName'] for row in tables_df.collect()]\n",
    "    \n",
    "    print(f\"üìã Found {len(all_tables)} tables in lakehouse:\")\n",
    "    for i, table in enumerate(all_tables, 1):\n",
    "        print(f\"  {i:2d}. {table}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error getting tables: {str(e)}\")\n",
    "    all_tables = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d69db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4\n",
    "#  Generate CREATE TABLE statements\n",
    "if all_tables:\n",
    "    output_content = []\n",
    "    \n",
    "    # Add header\n",
    "    output_content.append(\"# Generated CREATE TABLE Statements\")\n",
    "    output_content.append(f\"# Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    output_content.append(f\"# Total tables: {len(all_tables)}\")\n",
    "    output_content.append(f\"# Target schema: {TARGET_SCHEMA_NAME}\")\n",
    "    output_content.append(\"\")\n",
    "    output_content.append(\"# Configuration\")\n",
    "    output_content.append(f'SCHEMA_NAME = \"{TARGET_SCHEMA_NAME}\"')\n",
    "    output_content.append('spark.sql(f\"CREATE DATABASE IF NOT EXISTS {SCHEMA_NAME}\")')\n",
    "    output_content.append('print(f\"‚úÖ {SCHEMA_NAME} schema ready!\")')\n",
    "    output_content.append(\"\")\n",
    "    \n",
    "    successful_tables = 0\n",
    "    failed_tables = []\n",
    "    \n",
    "    for i, table_name in enumerate(all_tables, 1):\n",
    "        try:\n",
    "            print(f\"üîÑ Processing table {i}/{len(all_tables)}: {table_name}\")\n",
    "            \n",
    "            # Get table schema\n",
    "            describe_df = spark.sql(f\"DESCRIBE {table_name}\")\n",
    "            columns = describe_df.collect()\n",
    "            \n",
    "            # Filter valid columns\n",
    "            valid_columns = [col for col in columns \n",
    "                           if not col['col_name'].startswith('#') and col['col_name'].strip() != '']\n",
    "            \n",
    "            if valid_columns:\n",
    "                # Generate CREATE TABLE statement\n",
    "                output_content.append(f\"# {i}. Create {table_name} table\")\n",
    "                output_content.append('create_table_sql = f\"\"\"')\n",
    "                output_content.append(f'CREATE TABLE IF NOT EXISTS {{SCHEMA_NAME}}.{table_name} (')\n",
    "                \n",
    "                # Add column definitions\n",
    "                for j, col in enumerate(valid_columns):\n",
    "                    col_name = col['col_name']\n",
    "                    data_type = col['data_type']\n",
    "                    \n",
    "                    # Standardize data types\n",
    "                    if 'bigint' in data_type.lower():\n",
    "                        data_type = 'BIGINT'\n",
    "                    elif 'int' in data_type.lower():\n",
    "                        data_type = 'INT'\n",
    "                    elif 'string' in data_type.lower():\n",
    "                        data_type = 'STRING'\n",
    "                    elif 'double' in data_type.lower():\n",
    "                        data_type = 'DOUBLE'\n",
    "                    elif 'decimal' in data_type.lower():\n",
    "                        data_type = data_type.upper()\n",
    "                    elif 'boolean' in data_type.lower():\n",
    "                        data_type = 'BOOLEAN'\n",
    "                    elif 'timestamp' in data_type.lower():\n",
    "                        data_type = 'TIMESTAMP'\n",
    "                    elif 'date' in data_type.lower():\n",
    "                        data_type = 'DATE'\n",
    "                    elif 'binary' in data_type.lower():\n",
    "                        data_type = 'BINARY'\n",
    "                    \n",
    "                    # Add comma for all but last column\n",
    "                    comma = \",\" if j < len(valid_columns) - 1 else \"\"\n",
    "                    output_content.append(f'    {col_name} {data_type}{comma}')\n",
    "                \n",
    "                output_content.append(')')\n",
    "                output_content.append('USING DELTA')\n",
    "                output_content.append('\"\"\"')\n",
    "                output_content.append('spark.sql(create_table_sql)')\n",
    "                output_content.append(f'print(f\"‚úÖ {{SCHEMA_NAME}}.{table_name} table created!\")')\n",
    "                output_content.append(\"\")\n",
    "                \n",
    "                successful_tables += 1\n",
    "                \n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  No valid columns found for table: {table_name}\")\n",
    "                failed_tables.append(table_name)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing table {table_name}: {str(e)}\")\n",
    "            failed_tables.append(table_name)\n",
    "    \n",
    "    print(f\"\\nüìä Processing Summary:\")\n",
    "    print(f\"   ‚Ä¢ Total tables: {len(all_tables)}\")\n",
    "    print(f\"   ‚Ä¢ Successful: {successful_tables}\")\n",
    "    print(f\"   ‚Ä¢ Failed: {len(failed_tables)}\")\n",
    "    \n",
    "    if failed_tables:\n",
    "        print(f\"   ‚Ä¢ Failed tables: {', '.join(failed_tables)}\")\n",
    "    \n",
    "else:\n",
    "    output_content = [\"# No tables found in lakehouse\"]\n",
    "    print(\"‚ö†Ô∏è  No tables found to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582163c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5\n",
    "# Display full generated content for manual copying\n",
    "print(\"üîç FULL GENERATED CONTENT:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"üìã Copy the content below and paste into your GeneratedCreateTablesStmts.ipynb:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    if 'output_content' in locals() and output_content:\n",
    "        full_content = \"\\n\".join(output_content)\n",
    "        \n",
    "        print(f\"üìä Content Statistics:\")\n",
    "        print(f\"   ‚Ä¢ Total lines: {len(output_content)}\")\n",
    "        print(f\"   ‚Ä¢ Total characters: {len(full_content)}\")\n",
    "        print(f\"   ‚Ä¢ First table: {all_tables[0] if all_tables else 'None'}\")\n",
    "        print(f\"   ‚Ä¢ Last table: {all_tables[-1] if all_tables else 'None'}\")\n",
    "        print(f\"   ‚Ä¢ Target schema: {TARGET_SCHEMA_NAME}\")\n",
    "        print()\n",
    "        \n",
    "        print(\"üìÑ GENERATED CREATE TABLE STATEMENTS:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(full_content)\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Content displayed successfully!\")\n",
    "        print(f\"üéØ Next Steps:\")\n",
    "        print(f\"   1. Copy the above content\")\n",
    "        print(f\"   2. Paste into GeneratedCreateTablesStmts.ipynb\")\n",
    "        print(f\"   3. Execute to create all {len(all_tables)} tables in {TARGET_SCHEMA_NAME} schema\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No content generated yet - run previous cells first\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error displaying content: {str(e)}\")\n",
    "    \n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba2d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6\n",
    "# Save output to a file in the same lakehouse, to folder and file defined in Step 2,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd6e896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
