{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "851d065c",
   "metadata": {},
   "source": [
    "# Databricks Sample Data Exploration\n",
    "\n",
    "## Overview\n",
    "This notebook explores available sample datasets in Azure Databricks workspace and validates data sources for our multi-tier architecture.\n",
    "\n",
    "## Steps\n",
    "1. **Step 1:** Check available databases\n",
    "2. **Step 2:** Explore TPC-H database tables\n",
    "3. **Step 3:** Test TPC-H data access and validation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4adee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Check Available Databases\n",
    "print(\"üîç STEP 1: AVAILABLE DATABASES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "databases = spark.sql(\"SHOW DATABASES\").collect()\n",
    "for db in databases:\n",
    "    print(f\"  üìÅ {db.databaseName}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Found {len(databases)} database(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d1e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Explore TPC-H Database\n",
    "print(\"üéØ STEP 2: EXPLORING TPC-H DATABASE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    spark.sql(\"USE tpch\")\n",
    "    print(\"‚úÖ 'tpch' database found!\")\n",
    "    \n",
    "    print(\"\\nüìä TABLES IN TPC-H DATABASE:\")\n",
    "    tables = spark.sql(\"SHOW TABLES\").collect()\n",
    "    for table in tables:\n",
    "        print(f\"  üìã {table.tableName}\")\n",
    "        \n",
    "    # Show table schemas for key tables\n",
    "    print(\"\\nüîç KEY TABLE SCHEMAS:\")\n",
    "    \n",
    "    print(\"\\nüë• CUSTOMER table schema:\")\n",
    "    spark.sql(\"DESCRIBE customer\").show()\n",
    "    \n",
    "    print(\"\\nüì¶ PART table schema:\")\n",
    "    spark.sql(\"DESCRIBE part\").show()\n",
    "    \n",
    "    print(\"\\nüõí ORDERS table schema:\")\n",
    "    spark.sql(\"DESCRIBE orders\").show()\n",
    "    \n",
    "    print(\"\\nüìã LINEITEM table schema:\")\n",
    "    spark.sql(\"DESCRIBE lineitem\").show()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå 'tpch' database not available: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90740e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Test TPC-H Data Access and Validation\n",
    "print(\"‚úÖ STEP 3: TPC-H DATA ACCESS AND VALIDATION TESTING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Use the real TPC-H database\n",
    "try:\n",
    "    spark.sql(\"USE tpch\")\n",
    "    tables = spark.sql(\"SHOW TABLES\").collect()\n",
    "    \n",
    "    print(\"üìã TPC-H tables with record counts:\")\n",
    "    for table in tables:\n",
    "        table_name = table.tableName\n",
    "        try:\n",
    "            count_df = spark.sql(f\"SELECT COUNT(*) as count FROM {table_name}\")\n",
    "            count = count_df.collect()[0][0]  # Get first row, first column\n",
    "            print(f\"  ‚úÖ {table_name}: {count} records\")\n",
    "        except Exception as count_error:\n",
    "            print(f\"  ‚ùå {table_name}: Error getting count - {count_error}\")\n",
    "\n",
    "    print(\"\\nüë• TPC-H CUSTOMER DATA PREVIEW:\")\n",
    "    spark.sql(\"SELECT c_custkey, c_name, c_mktsegment, c_nationkey FROM customer LIMIT 5\").show()\n",
    "    \n",
    "    print(\"\\nüì¶ TPC-H PART (PRODUCT) DATA PREVIEW:\")\n",
    "    spark.sql(\"SELECT p_partkey, p_name, p_brand, p_type, p_retailprice FROM part LIMIT 5\").show()\n",
    "    \n",
    "    print(\"\\nüõí TPC-H ORDERS DATA PREVIEW:\")\n",
    "    spark.sql(\"SELECT o_orderkey, o_custkey, o_orderstatus, o_totalprice, o_orderdate FROM orders LIMIT 5\").show()\n",
    "    \n",
    "    print(\"\\nüìã TPC-H LINEITEM DATA PREVIEW:\")\n",
    "    spark.sql(\"SELECT l_orderkey, l_partkey, l_quantity, l_extendedprice, l_discount FROM lineitem LIMIT 5\").show()\n",
    "    \n",
    "    print(\"\\nüîó TPC-H JOIN TEST (Customer + Orders + LineItems):\")\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            c.c_name,\n",
    "            o.o_orderkey,\n",
    "            o.o_totalprice,\n",
    "            o.o_orderstatus,\n",
    "            COUNT(l.l_orderkey) as line_items\n",
    "        FROM customer c\n",
    "        JOIN orders o ON c.c_custkey = o.o_custkey\n",
    "        JOIN lineitem l ON o.o_orderkey = l.l_orderkey\n",
    "        GROUP BY c.c_name, o.o_orderkey, o.o_totalprice, o.o_orderstatus\n",
    "        LIMIT 5\n",
    "    \"\"\").show()\n",
    "    \n",
    "    print(\"\\nüåç TPC-H NATION/REGION DATA:\")\n",
    "    spark.sql(\"SELECT n_name, r_name FROM nation n JOIN region r ON n.n_regionkey = r.r_regionkey LIMIT 10\").show()\n",
    "    \n",
    "    print(\"‚úÖ All TPC-H data access tests successful!\")\n",
    "    print(\"\\nüéØ PERFECT BRONZE TIER DATA FOR SOLUTION ACCELERATOR!\")\n",
    "    print(\"üìä This gives us realistic Customer, Product, Order data with different schemas\")\n",
    "    print(\"üîÑ Ready for Bronze ‚Üí Silver ‚Üí Gold pipeline development\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during TPC-H validation: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä TPC-H DATA EXPLORATION COMPLETE - READY FOR ARCHITECTURE!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
