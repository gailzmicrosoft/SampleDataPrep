{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8050b5d",
   "metadata": {},
   "source": [
    "# SalesLT to Bronze Lakehouse Copy\n",
    "\n",
    "**Objective**: Copy SalesLT tables from shortcuts in `Gaiye_Test_Lakehouse` to bronze layer in `RDS_Fabric_Foundry_workspace_Gaiye_Retail_Solution_Test_IDM_LH_bronze`\n",
    "\n",
    "**Setup Required**:\n",
    "1. Run this notebook in the bronze lakehouse: `RDS_Fabric_Foundry_workspace_Gaiye_Retail_Solution_Test_IDM_LH_bronze`\n",
    "2. Attach `Gaiye_Test_Lakehouse` as additional lakehouse\n",
    "3. Execute cells sequentially"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea05e035",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "print(\"✅ Libraries imported\")\n",
    "print(f\"📅 Started: {datetime.now()}\")\n",
    "print(\"🎯 Target: Files/bronze/saleslt/ in current lakehouse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263d42bc",
   "metadata": {},
   "source": [
    "## Step 2: Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81419d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check environment and available tables\n",
    "print(\"🔍 ENVIRONMENT CHECK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check Spark\n",
    "print(f\"✅ Spark version: {spark.version}\")\n",
    "\n",
    "# Check available tables\n",
    "tables_df = spark.sql(\"SHOW TABLES\").toPandas()\n",
    "print(f\"✅ Available tables: {len(tables_df)}\")\n",
    "\n",
    "# Look for SalesLT tables (shortcuts)\n",
    "expected_tables = ['address', 'customer', 'customeraddress', 'product', \n",
    "                  'productcategory', 'productdescription', 'productmodel',\n",
    "                  'productmodelproductdescription', 'salesorderdetail', 'salesorderheader']\n",
    "\n",
    "found_tables = []\n",
    "for table in expected_tables:\n",
    "    if table in tables_df['tableName'].str.lower().values:\n",
    "        found_tables.append(table)\n",
    "        print(f\"   ✅ Found: {table}\")\n",
    "    else:\n",
    "        print(f\"   ❌ Missing: {table}\")\n",
    "\n",
    "print(f\"\\n📊 Found {len(found_tables)} of {len(expected_tables)} expected tables\")\n",
    "\n",
    "if len(found_tables) == 0:\n",
    "    print(\"⚠️ No SalesLT tables found!\")\n",
    "    print(\"💡 Ensure Gaiye_Test_Lakehouse is attached as additional lakehouse\")\n",
    "else:\n",
    "    print(f\"🎉 Ready to copy {len(found_tables)} tables!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d9aecc",
   "metadata": {},
   "source": [
    "## Step 3: Test Write Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9701c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test write access to bronze layer\n",
    "print(\"🧪 TESTING WRITE ACCESS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Create test data\n",
    "    test_data = [(\"test\", datetime.now().isoformat())]\n",
    "    test_df = spark.createDataFrame(test_data, [\"status\", \"timestamp\"])\n",
    "    \n",
    "    # Test write to bronze location\n",
    "    test_path = \"Files/bronze/saleslt/_test\"\n",
    "    test_df.write.mode(\"overwrite\").parquet(test_path)\n",
    "    \n",
    "    # Verify read\n",
    "    verify_df = spark.read.parquet(test_path)\n",
    "    count = verify_df.count()\n",
    "    \n",
    "    # Clean up\n",
    "    dbutils.fs.rm(test_path, True)\n",
    "    \n",
    "    print(f\"✅ Write access confirmed\")\n",
    "    print(f\"✅ Test file created and read ({count} records)\")\n",
    "    print(f\"🎯 Ready to write to Files/bronze/saleslt/\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Write test failed: {str(e)}\")\n",
    "    print(f\"💡 Ensure you're in the correct bronze lakehouse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19199894",
   "metadata": {},
   "source": [
    "## Step 4: Copy Tables to Bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8570c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all available SalesLT tables to bronze layer\n",
    "print(\"🚀 COPYING TABLES TO BRONZE LAYER\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get available tables again\n",
    "tables_df = spark.sql(\"SHOW TABLES\").toPandas()\n",
    "expected_tables = ['address', 'customer', 'customeraddress', 'product', \n",
    "                  'productcategory', 'productdescription', 'productmodel',\n",
    "                  'productmodelproductdescription', 'salesorderdetail', 'salesorderheader']\n",
    "\n",
    "# Find available tables\n",
    "available_tables = []\n",
    "for table in expected_tables:\n",
    "    if table in tables_df['tableName'].str.lower().values:\n",
    "        available_tables.append(table)\n",
    "\n",
    "print(f\"📋 Copying {len(available_tables)} tables\")\n",
    "print(f\"🎯 Target: Files/bronze/saleslt/\")\n",
    "print()\n",
    "\n",
    "results = []\n",
    "total_rows = 0\n",
    "\n",
    "for i, table_name in enumerate(available_tables, 1):\n",
    "    print(f\"[{i}/{len(available_tables)}] Copying {table_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Read source table\n",
    "        source_df = spark.sql(f\"SELECT * FROM {table_name}\")\n",
    "        row_count = source_df.count()\n",
    "        \n",
    "        # Add metadata columns\n",
    "        bronze_df = source_df \\\n",
    "            .withColumn(\"_bronze_load_date\", lit(datetime.now().strftime(\"%Y-%m-%d\"))) \\\n",
    "            .withColumn(\"_bronze_load_timestamp\", lit(datetime.now().isoformat())) \\\n",
    "            .withColumn(\"_source_system\", lit(\"SalesLT\")) \\\n",
    "            .withColumn(\"_source_table\", lit(table_name)) \\\n",
    "            .withColumn(\"_load_method\", lit(\"shortcut_copy\"))\n",
    "        \n",
    "        # Write to bronze\n",
    "        bronze_path = f\"Files/bronze/saleslt/{table_name}\"\n",
    "        bronze_df.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").parquet(bronze_path)\n",
    "        \n",
    "        total_rows += row_count\n",
    "        results.append({\"table\": table_name, \"rows\": row_count, \"status\": \"success\"})\n",
    "        \n",
    "        print(f\"   ✅ {row_count:,} rows copied\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)[:80]\n",
    "        results.append({\"table\": table_name, \"rows\": 0, \"status\": \"failed\", \"error\": error_msg})\n",
    "        print(f\"   ❌ Failed: {error_msg}...\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Summary\n",
    "successful = [r for r in results if r[\"status\"] == \"success\"]\n",
    "failed = [r for r in results if r[\"status\"] == \"failed\"]\n",
    "\n",
    "print(\"🎉 COPY SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"✅ Successful: {len(successful)} tables\")\n",
    "print(f\"❌ Failed: {len(failed)} tables\")\n",
    "print(f\"📊 Total rows copied: {total_rows:,}\")\n",
    "\n",
    "if len(successful) > 0:\n",
    "    print(f\"\\n📁 Bronze layer structure:\")\n",
    "    print(f\"Files/bronze/saleslt/\")\n",
    "    for result in successful:\n",
    "        print(f\"├── {result['table']}/ ({result['rows']:,} rows)\")\n",
    "\n",
    "if len(failed) > 0:\n",
    "    print(f\"\\n⚠️ Failed copies:\")\n",
    "    for result in failed:\n",
    "        print(f\"❌ {result['table']}: {result.get('error', 'Unknown error')}\")\n",
    "\n",
    "print(f\"\\n🎯 Data location: Files/bronze/saleslt/ in current lakehouse\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9467e1a0",
   "metadata": {},
   "source": [
    "## Step 5: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2807c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the bronze layer data\n",
    "print(\"🔍 BRONZE LAYER VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Check Files directory\n",
    "    files_content = dbutils.fs.ls(\"Files/\")\n",
    "    print(f\"📁 Files directory contains {len(files_content)} items:\")\n",
    "    for item in files_content:\n",
    "        print(f\"   📂 {item.name}\")\n",
    "    \n",
    "    # Check bronze directory\n",
    "    if any(item.name.rstrip('/') == 'bronze' for item in files_content):\n",
    "        print(f\"\\n🎯 Bronze directory found! Checking contents...\")\n",
    "        \n",
    "        bronze_content = dbutils.fs.ls(\"Files/bronze/\")\n",
    "        print(f\"📁 Bronze directory contains {len(bronze_content)} items:\")\n",
    "        for item in bronze_content:\n",
    "            print(f\"   📂 {item.name}\")\n",
    "        \n",
    "        # Check saleslt directory\n",
    "        if any(item.name.rstrip('/') == 'saleslt' for item in bronze_content):\n",
    "            print(f\"\\n🎉 SalesLT directory found! Checking tables...\")\n",
    "            \n",
    "            saleslt_content = dbutils.fs.ls(\"Files/bronze/saleslt/\")\n",
    "            print(f\"📊 Found {len(saleslt_content)} table directories:\")\n",
    "            \n",
    "            total_validation_rows = 0\n",
    "            \n",
    "            for item in saleslt_content:\n",
    "                if item.isDir() and not item.name.startswith('_'):\n",
    "                    table_name = item.name.rstrip('/')\n",
    "                    try:\n",
    "                        # Read and count rows\n",
    "                        df = spark.read.parquet(f\"Files/bronze/saleslt/{table_name}\")\n",
    "                        row_count = df.count()\n",
    "                        total_validation_rows += row_count\n",
    "                        \n",
    "                        # Check for metadata columns\n",
    "                        metadata_cols = [col for col in df.columns if col.startswith('_')]\n",
    "                        \n",
    "                        print(f\"   ✅ {table_name}: {row_count:,} rows, {len(metadata_cols)} metadata columns\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"   ⚠️ {table_name}: Could not read ({str(e)[:30]}...)\")\n",
    "            \n",
    "            print(f\"\\n📊 VALIDATION SUMMARY:\")\n",
    "            print(f\"   📋 Table directories: {len([i for i in saleslt_content if i.isDir() and not i.name.startswith('_')])}\")\n",
    "            print(f\"   📊 Total validated rows: {total_validation_rows:,}\")\n",
    "            print(f\"   🎯 Location: Files/bronze/saleslt/\")\n",
    "            print(f\"\\n🎉 SUCCESS! Your SalesLT data is now in the bronze layer!\")\n",
    "        else:\n",
    "            print(f\"❌ SalesLT directory not found in bronze\")\n",
    "    else:\n",
    "        print(f\"❌ Bronze directory not found in Files\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Validation failed: {str(e)}\")\n",
    "    print(f\"💡 Check if the copy process completed successfully\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"🏁 Process completed at {datetime.now()}\")\n",
    "print(f\"📍 Bronze data location: Files/bronze/saleslt/\")\n",
    "print(f\"🎯 Target lakehouse: RDS_Fabric_Foundry_workspace_Gaiye_Retail_Solution_Test_IDM_LH_bronze\")\n",
    "print(f\"{'=' * 60}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
